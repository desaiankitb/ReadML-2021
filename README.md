# Beginner 
1. Introduction to Machine Learning  
	- Cassie Kozyrkov, Head of Decision Intelligence, Google. 
		- [Blog](https://kozyrkov.medium.com/)
		- [Videos YT Playlist](http://bit.ly/mfml_000)
2. [14 Different Types of Learning in Machine Learning](https://machinelearningmastery.com/types-of-learning-in-machine-learning/)
3. [Understanding GPT-3 In 5 Minutes](https://towardsdatascience.com/understanding-gpt-3-in-5-minutes-7fe35c3a1e52)
	- There are hundreds of articles about GPT-3. Here’s a 5-min compilation of everything there’s to know about it.
4. https://www.youtube.com/watch?v=2fsmSccdNc4 
	- Your machine learning project needs analysts too. What happens if you don't include analytics in your machine learning / AI workflow? In a nutshell, your project will take longer. It might even take forever. To understand how analysts can help speed things up for you, dive into this video!
5. (12 (actually-13) Steps to Applied AI)[https://medium.com/swlh/12-steps-to-applied-ai-2fdad7fdcdf3] 



# Intermediate 
1. [Stanford Vision Lab](http://vision.stanford.edu/teaching.html)
2. [NER vs BERT for person name identification](https://towardsdatascience.com/superior-person-name-recognition-with-pre-built-google-bert-e6215186eae0)

# Advanced
1. [Patterns for Personalization in Recommendations and Search](https://eugeneyan.com/writing/patterns-for-personalization/) 
2. [F8 2019: Facebook: Product Optimization with Adaptive Experimentation](https://www.youtube.com/watch?v=2c8YX0E8Qhw) 
	- [link](https://ax.dev/) 
	- Learn how Facebook uses adaptive experimentation, an AI-enabled testing approach, to optimize products, infrastructure, machine learning models, marketing campaigns and more. We'll cover the basic concepts behind adaptive experimentation, where it can be used, and how to use it in conjunction with Facebook's newly released open source packages, Ax and botorch.
3. [AugLy: A new data augmentation library to help build more robust AI models](https://machinelearningmastery.com/types-of-learning-in-machine-learning/)
	- Data Augmentation can help us with robust model testing for any AI jobs. AugLy helps us to augment the data of any type and in a way help to build the robust models. \#deeplearning
	- Facebook AI Research recently opensourced AugLy - one stop \#python library for \#machinelearning Data Augmentation. It supports Image, Video, Text and Audio with 100-ish augmentations.
	- Demo: https://lnkd.in/gXh8yst
	- Announcement: https://lnkd.in/gQqsw4S
	- Just, `pip install augly`
4. EXPLAINABILITY in MACHINE LEARNING EXPLAINED by Prof. Hima Lakkaruju.

	- If you have less than 3 hours to spare & want to learn (almost) everything about state-of-the-art explainable ML, please read on! Below, I am sharing info about 4 of the recent tutorials on explainability presented at #NeurIPS, #AAAI, #FAccT, and #CHIL conferences. (@june'21)

	- NeurIPS 2020: (2 hours 46 mins) TUTORIAL discusses various types of explanation methods, their limitations, evaluation frameworks, applications to domains such as decision making/nlp/vision, and open problems.
		- Slides and Video: https://explainml-tutorial.github.io/neurips20

	- AAAI 2021: Shorter tutorial at AAAI 2021 (1 hour 32 mins). This one discusses different explanation methods, their limitations, evaluation, and open problems.
		- Slides and video: https://explainml-tutorial.github.io/aaai21 

	- FAccT 2021: Ethical/practical implications of explainability along with a gentle intro to the topic? "Explainable ML in the Wild" (1 hr 31 mins) might be helpful.
		- Slides: (Link)[https://docs.google.com/presentation/d/10a0PNKwoV3a1XChzvY-T1mWudtzUIZi3sCMzVwGSYfM/edit#slide=id.p]
		- Video: (link)[https://www.youtube.com/watch?v=K6-ujR_67eY]

	- CHIL 2021: 1 hour tutorial on explainability gives a quick overview of various state-of-the-art methods, their limitations, open problems.
		- Slides: (link)[https://drive.google.com/file/d/1xn2dCDAeEEhB_rex202KxMPqIPj31fZ4/view] 
		- Video: (link)[https://www.chilconference.org/tutorial_T04.html]

	- Full fledged seminar course on explainability in ML at Harvard University. 
	- Last year's version of the course:  (link)[https://interpretable-ml-class.github.io/]

